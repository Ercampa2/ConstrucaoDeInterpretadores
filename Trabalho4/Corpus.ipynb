{"cells":[{"cell_type":"markdown","source":["Enzo Ramon Campa\n","\n","Sua  tarefa  será  transformar  um  conjunto  de  5  sites,  sobre  o  tema  de  processamento  de \n","linguagem natural em um conjunto de cinco listas distintas de sentenças. Ou seja, você fará uma função \n","que, usando a biblioteca Beautifull Soap, faça a requisição de uma url, e extrai todas as sentenças desta \n","url. Duas condições são importantes:  \n","a) A página web (url) deve apontar para uma página web em inglês contendo, não menos que \n","1000 palavras.  \n","b) O texto desta página deverá ser transformado em um array de senteças.  \n"," \n","Para separar as sentenças você pode usar os sinais de pontuação ou as funções da biblibioteca \n","Spacy. \n","\n"],"metadata":{"id":"Ymhc4Gq99c1Q"},"id":"Ymhc4Gq99c1Q"},{"cell_type":"code","execution_count":null,"id":"db807513","metadata":{"id":"db807513"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import re\n","\n","import spacy\n","npl = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":null,"id":"43c2a540","metadata":{"id":"43c2a540","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665341511577,"user_tz":180,"elapsed":1073,"user":{"displayName":"Enzo Campa","userId":"14794698325374388710"}},"outputId":"9a308d83-a1fb-4cf7-c1e2-27bae2ede67d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Natural language processing (NLP) is the ability of a computer program to understand human language as it is spoken and written -- referred to as natural language., It is a component of artificial intelligence (AI)., NLP has existed for more than 50 years and has roots in the field of linguistics., It has a variety of real-world applications in a number of fields, including medical research, search engines and business intelligence., NLP enables computers to understand natural language as humans do., Whether the language is spoken or written, natural language processing uses artificial intelligence to take real-world input, process it, and make sense of it in a way a computer can understand., Just as humans have different sensors -- such as ears to hear and eyes to see -- computers have programs to read and microphones to collect audio., And just as humans have a brain to process that input, computers have a program to process their respective inputs., At some point in processing, the input is converted to code that the computer can understand.  , There are two main phases to natural language processing: data preprocessing and algorithm development., Data preprocessing involves preparing and \"cleaning\" text data for machines to be able to analyze it., preprocessing puts data in workable form and highlights features in the text that an algorithm can work with., There are several ways this can be done, including:, This article is part of, Download this entire guide for FREE now!, Once the data has been preprocessed, an algorithm is developed to process it., There are many different natural language processing algorithms, but two main types are commonly used:, Businesses use massive quantities of unstructured, text-heavy data and need a way to efficiently process it., A lot of the information created online and stored in databases is natural human language, and until recently, businesses could not effectively analyze this data., This is where natural language processing is useful., The advantage of natural language processing can be seen when considering the following two statements: \"Cloud computing insurance should be part of every service-level agreement,\" and, \"A good SLA ensures an easier night's sleep -- even in the cloud.\", If a user relies on natural language processing for search, the program will recognize that cloud computing is an entity, that cloud is an abbreviated form of cloud computing and that SLA is an industry acronym for service-level agreement., These are the types of vague elements that frequently appear in human language and that machine learning algorithms have historically been bad at interpreting., Now, with improvements in deep learning and machine learning methods, algorithms can effectively interpret them., These improvements expand the breadth and depth of data that can be analyzed., Syntax and semantic analysis are two main techniques used with natural language processing., Syntax is the arrangement of words in a sentence to make grammatical sense., NLP uses syntax to assess meaning from a language based on grammatical rules., Syntax techniques include:, Semantics involves the use of and meaning behind words., Natural language processing applies algorithms to understand the meaning and structure of sentences., Semantics techniques include:, Current approaches to natural language processing are based on deep learning, a type of AI that examines and uses patterns in data to improve a program's understanding., Deep learning models require massive amounts of labeled data for the natural language processing algorithm to train on and identify relevant correlations, and assembling this kind of big data set is one of the main hurdles to natural language processing., Earlier approaches to natural language processing involved a more rules-based approach, where simpler machine learning algorithms were told what words and phrases to look for in text and given specific responses when those phrases appeared., But deep learning is a more flexible, intuitive approach in which algorithms learn to identify speakers' intent from many examples -- almost like how a child would learn human language., Three tools used commonly for natural language processing include Natural Language Toolkit (NLTK), Gensim and Intel natural language processing Architect., NLTK is an open source Python module with data sets and tutorials., Gensim is a Python library for topic modeling and document indexing., Intel NLP Architect is another Python library for deep learning topologies and techniques., Some of the main functions that natural language processing algorithms perform are:, The functions listed above are used in a variety of real-world applications, including:, Research being done on natural language processing revolves around search, especially Enterprise search., This involves having users query data sets in the form of a question that they might pose to another person., The machine interprets the important elements of the human language sentence, which correspond to specific features in a data set, and returns an answer., NLP can be used to interpret free, unstructured text and make it analyzable., There is a tremendous amount of information stored in free text files, such as patients' medical records., Before deep learning-based NLP models, this information was inaccessible to computer-assisted analysis and could not be analyzed in any systematic way., With NLP analysts can sift through massive amounts of free text to find relevant information., Sentiment analysis is another primary use case for NLP., Using sentiment analysis, data scientists can assess comments on social media to see how their business's brand is performing, or review notes from customer service teams to identify areas where people want the business to perform better., The main benefit of NLP is that it improves the way humans and computers communicate with each other., The most direct way to manipulate a computer is through code -- the computer's language., By enabling computers to understand human language, interacting with computers becomes much more intuitive for humans., Other benefits include:, There are a number of challenges of natural language processing and most of them boil down to the fact that natural language is ever-evolving and always somewhat ambiguous., They include:, NLP draws from a variety of disciplines, including computer science and computational linguistics developments dating back to the mid-20th century., Its evolution included the following major milestones:, Natural language processing plays a vital part in technology and the way humans interact with it., It is used in many real-world applications in both the business and consumer spheres, including chatbots, cybersecurity, search engines and big data analytics., Though not without its challenges, NLP is expected to continue to be an important part of both industry and everyday life., Although there are doubts, natural language processing is making significant strides in the medical imaging field., Learn how radiologists are using AI and NLP in their practice to review their work and compare cases., The release is the vendor's first since being acquired by Idera in early 2022 and builds on natural language query features it ..., The database vendor plans to use the capital to fund product development, global expansion and marketing as well as keep some in ..., Two years after starting a pilot program with the data and analytics vendor, the accounting firm has saved more than 100,000 work..., The three antitrust bills passed by the U.S. House of Representatives would funnel more money to antitrust law enforcers, as well..., The $100 billion plan aims to bring businesses and thousands of workers to the Syracuse, N.Y., area -- and boost the chip supply ..., Liberty Mutual Insurance's next CIO, Monica Caldas, shares new ways of solving the IT talent problem and explains why soft skills..., The database vendor extended its namesake database platform to support machine learning applications with its revamped ..., At Big Data London, data quality and intelligence took center stage as companies strive for fast and efficient delivery of ..., The streaming data platform vendor added a stream designer and new governance capabilities to its cloud service for organizations..., NetSuite debuted several new features for CPQ, workforce management, embedded banking and warehouse management for its cloud ERP ..., New regulations including the Fair Repair Act coupled with factors like consumer demand for sustainability are motivating ..., Users often combine RFID and IoT, but the two technologies are different in some important ways., Learn more about RFID vs. IoT ...]\n"]}],"source":["page1_sentences = []\n","\n","URL = \"https://www.techtarget.com/searchenterpriseai/definition/natural-language-processing-NLP\"\n","\n","page = requests.get(URL)\n","soup = BeautifulSoup(page.content, 'html.parser')\n","paragraphs = soup.find_all(\"p\")\n","\n","for paragraph in paragraphs:\n","  if(paragraph.find(\"span\") == None):\n","    text = npl(paragraph.get_text())\n","    for sentence in text.sents:\n","      page1_sentences.append(sentence)\n","\n","print(page1_sentences)"]},{"cell_type":"code","execution_count":null,"id":"7001a6f5","metadata":{"id":"7001a6f5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665341520828,"user_tz":180,"elapsed":1243,"user":{"displayName":"Enzo Campa","userId":"14794698325374388710"}},"outputId":"afc5b608-d4e3-4b41-c554-ca1b435f0a97"},"outputs":[{"output_type":"stream","name":"stdout","text":["[The conventional wisdom around AI has been that while computers have the edge over humans when it comes to data-driven decision making, it can’t compete on qualitative tasks., That, however, is changing., Natural language processing (NLP) tools have advanced rapidly and can help with writing, coding, and discipline-specific reasoning., Companies that want to make use of this new tech should focus on the following: 1) Identify text data assets and determine how the latest techniques can be leveraged to add value for your firm, 2) understand how you might leverage AI-based language technologies to make better decisions or reorganize your skilled labor, 3) begin incorporating new language-based AI tools for a variety of tasks to better understand their capabilities, and 4) don’t underestimate the transformative potential of AI., Until recently, the conventional wisdom was that while AI was better than humans at data-driven decision making tasks, it was still inferior to humans for cognitive and creative ones., But in the past two years language-based AI has advanced by leaps and bounds, changing common notions of what this technology can do., The most visible advances have been in what’s called “natural language processing” (NLP), the branch of AI focused on how computers can process language like humans do., It has been used to write an article for The Guardian, and AI-authored blog posts have gone viral — feats that weren’t possible a few years ago., AI even excels at cognitive tasks like programming where it is able to generate programs for simple video games from human instructions., Yet while these stunts may be attention grabbing, are they really indicative of what this tech can do for businesses?, The best known natural language processing tool is GPT-3, from OpenAI, which uses AI and statistics to predict the next word in a sentence based on the preceding words., NLP practitioners call tools like this “language models,” and they can be used for simple analytics tasks, such as classifying documents and analyzing the sentiment in blocks of text, as well as more advanced tasks, such as answering questions and summarizing reports., Language models are already reshaping traditional text analytics, but GPT-3 was an especially pivotal language model because, at 10x larger than any previous model upon release, it was the first large language model, which enabled it to perform even more advanced tasks like programming and solving high school–level math problems., The latest version, called InstructGPT, has been fine-tuned by humans to generate responses that are much better aligned with human values and user intentions, and Google’s latest model shows further impressive breakthroughs on language and reasoning., For businesses, the three areas where GPT-3 has appeared most promising are writing, coding, and discipline-specific reasoning., OpenAI, the Microsoft-funded creator of GPT-3, has developed a GPT-3-based language model intended to act as an assistant for programmers by generating code from natural language input., This tool, Codex, is already powering products like Copilot for Microsoft’s subsidiary GitHub and is capable of creating a basic video game simply by typing instructions., This transformative capability was already expected to change the nature of how programmers do their jobs, but models continue to improve — the latest from Google’s DeepMind AI lab, for example, demonstrates the critical thinking and logic skills necessary to outperform most humans in programming competitions., Models like GPT-3 are considered to be foundation models — an emerging AI research area — which also work for other types of data such as images and video., Foundation models can even be trained on multiple forms of data at the same time, like OpenAI’s DALL·E 2, which is trained on language and images to generate high-resolution renderings of imaginary scenes or objects simply from text prompts., Due to their potential to transform the nature of cognitive work, economists expect that foundation models may affect every part of the economy and could lead to increases in economic growth similar to the industrial revolution., In my own work, I’ve been looking at how GPT-3-based tools can assist researchers in the research process., I am currently working with Ought, a San Francisco company developing an open-ended reasoning tool (called Elicit) that is intended to help researchers answer questions in minutes or hours instead of weeks or months., Elicit is designed for a growing number of specific tasks relevant to research, like summarization, data labeling, rephrasing, brainstorming, and literature reviews., I’ve found — not surprisingly — that Elicit works better for some tasks than others., Tasks like data labeling and summarization are still rough around the edges, with noisy results and spotty accuracy, but research from Ought and research from OpenAI shows promise for the future., For example, the rephrase task is useful for writing, but the lack of integration with word processing apps renders it impractical for now., Brainstorming tasks are great for generating ideas or identifying overlooked topics, and despite the noisy results and barriers to adoption, they are currently valuable for a variety of situations., Yet, of all the tasks Elicit offers, I find the literature review the most useful., Because Elicit is an AI research assistant, this is sort of its bread-and-butter, and when I need to start digging into a new research topic, it has become my go-to resource., All of this is changing how I work., I spend much less time trying to find existing content relevant to my research questions because its results are more applicable than other, more traditional interfaces for academic search like Google Scholar., I am also beginning to integrate brainstorming tasks into my work as well, and my experience with these tools has inspired my latest research, which seeks to utilize foundation models for supporting strategic planning., You are certainly aware of the value of data, but you still may be overlooking some essential data assets if you are not utilizing text analytics and NLP throughout your organization., Text data is certainly valuable for customer experience management and understanding the voice of the customer, but think about other text data assets in your organization: emails, analysts’ reports, contracts, press releases, archives — even meetings and phone calls can be transcribed., There is so much text data, and you don’t need advanced models like GPT-3 to extract its value., Hugging Face, an NLP startup, recently released AutoNLP, a new tool that automates training models for standard text analytics tasks by simply uploading your data to the platform., The data still needs labels, but far fewer than in other applications., Because many firms have made ambitious bets on AI only to struggle to drive value into the core business, remain cautious to not be overzealous., This can be a good first step that your existing machine learning engineers — or even talented data scientists — can manage., To take the next step, again, identify your data assets., Many sectors, and even divisions within your organization, use highly specialized vocabularies., Through a combination of your data assets and open datasets, train a model for the needs of specific sectors or divisions., Think of finance., You do not want a model specialized in finance., You want a model customized for commercial banking, or for capital markets., And data is critical, but now it is unlabeled data, and the more the better., Specialized models like this can unlock untold value for your firm., Language-based AI won’t replace jobs, but it will automate many tasks, even for decision makers., Startups like Verneek are creating Elicit-like tools to enable everyone to make data-informed decisions., These new tools will transcend traditional business intelligence and will transform the nature of many roles in organizations — programmers are just the beginning., You need to start understanding how these technologies can be used to reorganize your skilled labor., The next generation of tools like OpenAI’s Codex will lead to more productive programmers, which likely means fewer dedicated programmers and more employees with modest programming skills using them for an increasing number of more complex tasks., This may not be true for all software developers, but it has significant implications for tasks like data processing and web development., Right now tools like Elicit are just emerging, but they can already be useful in surprising ways., In fact, the previous suggestion was inspired by one of Elicit’s brainstorming tasks conditioned on my other three suggestions., The original suggestion itself wasn’t perfect, but it reminded me of some critical topics that I had overlooked, and I revised the article accordingly., In organizations, tasks like this can assist strategic thinking or scenario-planning exercises., Although there is tremendous potential for such applications, right now the results are still relatively crude, but they can already add value in their current state., The bottom line is that you need to encourage broad adoption of language-based AI tools throughout your business., It is difficult to anticipate just how these tools might be used at different levels of your organization, but the best way to get an understanding of this tech may be for you and other leaders in your firm to adopt it yourselves., Don’t bet the boat on it because some of the tech may not work out, but if your team gains a better understanding of what is possible, then you will be ahead of the competition., Remember that while current AI might not be poised to replace managers, managers who understand AI are poised to replace managers who don’t., Large foundation models like GPT-3 exhibit abilities to generalize to a large number of tasks without any task-specific training., The recent progress in this tech is a significant step toward human-level generalization and general artificial intelligence that are the ultimate goals of many AI researchers, including those at OpenAI and Google’s DeepMind., Such systems have tremendous disruptive potential that could lead to AI-driven explosive economic growth, which would radically transform business and society., While you may still be skeptical of radically transformative AI like artificial general intelligence, it is prudent for organizations’ leaders to be cognizant of early signs of progress due to its tremendous disruptive potential., Consider that former Google chief Eric Schmidt expects general artificial intelligence in 10–20 years and that the UK recently took an official position on risks from artificial general intelligence., Had organizations paid attention to Anthony Fauci’s 2017 warning on the importance of pandemic preparedness, the most severe effects of the pandemic and ensuing supply chain crisis may have been avoided., Ignoring the transformative potential of AI also carries risks, and similar to the supply chain crisis, firms’ inaction or irresponsible use of AI could have widespread and damaging effects on society (e.g., increasing inequality or domain-specific risks from automation)., However, unlike the supply chain crisis, societal changes from transformative AI will likely be irreversible and could even continue to accelerate., Organizations should begin preparing now not only to capitalize on transformative AI, but to do their part to avoid undesirable futures and ensure that advanced AI is used to equitably benefit society., Powerful generalizable language-based AI tools like Elicit are here, and they are just the tip of the iceberg; multimodal foundation model-based tools are poised to transform business in ways that are still difficult to predict., To begin preparing now, start understanding your text data assets and the variety of cognitive tasks involved in different roles in your organization., Aggressively adopt new language-based AI technologies; some will work well and others will not, but your employees will be quicker to adjust when you move on to the next., And don’t forget to adopt these technologies yourself — this is the best way for you to start to understand their future roles in your organization.]\n"]}],"source":["page2_sentences = []\n","URL = \"https://hbr.org/2022/04/the-power-of-natural-language-processing\"\n","\n","page = requests.get(URL)\n","soup = BeautifulSoup(page.content, 'html.parser')\n","paragraphs = soup.find_all(\"p\")\n","\n","for paragraph in paragraphs:\n","  text = npl(paragraph.get_text())\n","  for sentence in text.sents:\n","    page2_sentences.append(str(sentence))\n","\n","print(page2_sentences)"]},{"cell_type":"code","source":["page3_sentences = []\n","URL = \"https://monkeylearn.com/natural-language-processing/\"\n","\n","page = requests.get(URL)\n","soup = BeautifulSoup(page.content, 'html.parser')\n","paragraphs = soup.find_all(\"p\")\n","\n","for paragraph in paragraphs:\n","  if paragraph.find(\"img\") == None :\n","    text = npl(paragraph.get_text())\n","    for sentence in text.sents:\n","      page3_sentences.append(str(sentence))\n","\n","print(page3_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XQSfEEkHAvi","executionInfo":{"status":"ok","timestamp":1665345274032,"user_tz":180,"elapsed":1523,"user":{"displayName":"Enzo Campa","userId":"14794698325374388710"}},"outputId":"852055ce-9197-486a-ea48-c0585ca6a00e"},"id":"2XQSfEEkHAvi","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Natural Language Processing (NLP) allows machines to break down and interpret human language., It’s at the core of tools we use every day – from translation software, chatbots, spam filters, and search engines, to grammar correction software, voice assistants, and social media monitoring tools., Start your NLP journey with no-code tools, In this guide, you’ll learn about the basics of Natural Language Processing and some of its challenges, and discover the most popular NLP applications in business.  , Finally, you’ll see for yourself just how easy it is to get started with code-free natural language processing tools.  , Natural Language Processing (NLP) is a field of Artificial Intelligence (AI) that makes human language intelligible to machines., NLP combines the power of linguistics and computer science to study the rules and structure of language, and create intelligent systems (run on machine learning and NLP algorithms) capable of understanding, analyzing, and extracting meaning from text and speech., NLP is used to understand the structure and meaning of human language by analyzing different aspects like syntax, semantics, pragmatics, and morphology., Then, computer science transforms this linguistic knowledge into rule-based, machine learning algorithms that can solve specific problems and perform desired tasks., Take Gmail, for example., Emails are automatically categorized as Promotions, Social, Primary, or Spam, thanks to an NLP task called keyword extraction., By “reading” words in subject lines and associating them with predetermined tags, machines automatically learn which category to assign emails., There are many benefits of NLP, but here are just a few top-level benefits that will help your business become more competitive:, Using text vectorization, NLP tools transform text into something a machine can understand, then machine learning algorithms are fed training data and expected outputs (tags) to train machines to make associations between a particular input and its corresponding output.\n",", Machines then use statistical analysis methods to build their own “knowledge bank” and discern which features best represent the texts, before making predictions for unseen data (new texts):, Ultimately, the more data these NLP algorithms are fed, the more accurate the text analysis models will be., Sentiment analysis (seen in the above chart) is one of the most popular NLP tasks, where machine learning models are trained to classify text by polarity of opinion (positive, negative, neutral, and everywhere in between)., Try out sentiment analysis for yourself by typing text in the NLP model, below, The biggest advantage of machine learning models is their ability to learn on their own, with no need to define manual rules., You just need a set of relevant training data with several examples for the tags you want to analyze., And with advanced deep learning algorithms, you’re able to chain together multiple natural language processing tasks, like sentiment analysis, keyword extraction, topic classification, intent detection, and more, to work simultaneously for super fine-grained results., Many natural language processing tasks involve syntactic and semantic analysis, used to break down human language into machine-readable chunks., Syntactic analysis, also known as parsing or syntax analysis, identifies the syntactic structure of a text and the dependency relationships between words, represented on a diagram called a parse tree., Semantic analysis focuses on identifying the meaning of language., However, since language is polysemic and ambiguous, semantics is considered one of the most challenging areas in NLP., Semantic tasks analyze the structure of sentences, word interactions, and related concepts, in an attempt to discover the meaning of words, as well as understand the topic of a text., Below, we’ve listed some of the main sub-tasks of both semantic and syntactic analysis:, Tokenization is an essential task in natural language processing used to break up a string of words into semantically useful units called tokens., Sentence tokenization splits sentences within a text, and word tokenization splits words within a sentence., Generally, word tokens are separated by blank spaces, and sentence tokens by stops., However, you can perform high-level tokenization for more complex structures, like words that often go together, otherwise known as collocations (e.g., New York)., An example of how word tokenization simplifies text:, Here’s an example of how word tokenization simplifies text:, Customer service couldn’t be better!, = “customer service” “could” “not” “be” “better”., Part-of-speech tagging (abbreviated as PoS tagging) involves adding a part of speech category to each token within a text., Some common PoS tags are verb, adjective, noun, pronoun, conjunction, preposition, intersection, among others., In this case, the example above would look like this:, “Customer service”: NOUN, “could”: VERB, “not”: ADVERB, be”: VERB, “better”: ADJECTIVE, “!”: PUNCTUATION, PoS tagging is useful for identifying relationships between words and, therefore, understand the meaning of sentences., Dependency grammar refers to the way the words in a sentence are connected., A dependency parser, therefore, analyzes how ‘head words’ are related and modified by other words too understand the syntactic structure of a sentence:, Constituency Parsing aims to visualize the entire syntactic structure of a sentence by identifying phrase structure grammar., It consists of using abstract terminal and non-terminal nodes associated to words, as shown in this example:, You can try different parsing algorithms and strategies depending on the nature of the text you intend to analyze, and the level of complexity you’d like to achieve., When we speak or write, we tend to use inflected forms of a word (words in their different grammatical forms)., To make these words easier for computers to understand, NLP uses lemmatization and stemming to transform them back to their root form., The word as it appears in the dictionary – its root form – is called a lemma., For example, the terms \"is, are, am, were, and been,” are grouped under the lemma ‘be.’, So, if we apply this lemmatization to “African elephants have four nails on their front feet,” the result will look something like this:, African elephants have four nails on their front feet = “African,” “elephant,” “have,” “4”, “nail,” “on,” “their,” “foot”], This example is useful to see how the lemmatization changes the sentence using its base form (e.g., the word \"feet\"\" was changed to \"foot\")., When we refer to stemming, the root form of a word is called a stem., Stemming \"trims\" words, so word stems may not always be semantically correct., For example, stemming the words “consult,” “consultant,” “consulting,” and “consultants” would result in the root form “consult.”, While lemmatization is dictionary-based and chooses the appropriate lemma based on context, stemming operates on single words without considering the context., For example, in the sentence:, “This is better”, The word “better” is transformed into the word “good” by a lemmatizer but is unchanged by stemming., Even though stemmers can lead to less-accurate results, they are easier to build and perform faster than lemmatizers., But lemmatizers are recommended if you're seeking more precise linguistic rules., Removing stop words is an essential step in NLP text processing., It involves filtering out high-frequency words that add little or no semantic value to a sentence, for example, which, to, at, for, is, etc., You can even customize lists of stopwords to include words that you want to ignore., Let’s say you want to classify customer service tickets based on their topics., In this example: “Hello, I’m having trouble logging in with my new password”, it may be useful to remove stop words like “hello”, “I”, “am”, “with”, “my”, so you’re left with the words that help you understand the topic of the ticket: “trouble”, “logging in”, “new”, “password”., Depending on their context, words can have different meanings., Take the word “book”, for example:, There are two main techniques that can be used for word sense disambiguation (WSD): knowledge-based (or dictionary approach) or supervised approach., The first one tries to infer meaning by observing the dictionary definitions of ambiguous terms within a text, while the latter is based on natural language processing algorithms that learn from training data., Named entity recognition is one of the most popular tasks in semantic analysis and involves extracting entities from within a text., Entities can be  names, places, organizations, email addresses, and more., Relationship extraction, another sub-task of NLP, goes one step further and finds relationships between two nouns., For example, in the phrase “Susan lives in Los Angeles,” a person (Susan) is related to a place (Los Angeles) by the semantic category “lives in.”, Text classification is the process of understanding the meaning of unstructured text and organizing it into predefined categories (tags)., One of the most popular text classification tasks is sentiment analysis, which aims to categorize unstructured data by sentiment., Other classification tasks include intent detection, topic modeling, and language detection., There are many challenges in Natural language processing but one of the main reasons NLP is difficult is simply because human language is ambiguous., Even humans struggle to analyze and classify human language correctly., Take sarcasm, for example., How do you teach a machine to understand an expression that’s used to say the opposite of what’s true?, While humans would easily detect sarcasm in this comment, below, it would be challenging to teach a machine how to interpret this phrase:, “If I had a dollar for every smart thing you say, I’d be poor.”, To fully comprehend human language, data scientists need to teach NLP tools to look beyond definitions and word order, to understand context, word ambiguities, and other complex concepts connected to messages.\n",", But, they also need to consider other aspects, like culture, background, and gender, when fine-tuning natural language processing models., Sarcasm and humor, for example, can vary greatly from one country to the next., Natural language processing and powerful machine learning algorithms (often multiple used in collaboration) are improving, and bringing order to the chaos of human language, right down to concepts like sarcasm., We are also starting to see new trends in NLP, so we can expect NLP to revolutionize the way humans and technology collaborate in the near future and beyond., Although natural language processing continues to evolve, there are already many ways in which it is being used today., Most of the time you’ll be exposed to natural language processing without even realizing it., Often, NLP is running in the background of the tools and applications we use everyday, helping businesses improve our experiences., Below, we've highlighted some of the most common and most powerful uses of natural language processing in everyday life:, As mentioned above, email filters are one of the most common and most basic uses of NLP., When they were first introduced, they weren’t entirely accurate, but with years of machine learning training on millions of data samples, emails rarely slip into the wrong inbox these days., The most common being Apple’s Siri and Amazon’s Alexa, virtual assistants use NLP machine learning technology to understand and automatically process voice requests., Natural language processing algorithms allow the assistants to be custom-trained by individual users with no additional input, to learn from previous interactions, recall related queries, and connect to other apps., The use of voice assistants is expected to continue to grow exponentially as they are used to control home security systems, thermostats, lights, and cars – even let you know what you’re running low on in the refrigerator., Whenever you do a simple Google search, you’re using NLP machine learning., They use highly trained algorithms that, not only search for related words, but for the intent of the searcher., Results often change on a daily basis, following trending queries and morphing right along with human language., They even learn to suggest topics and subjects related to your query that you may not have even realized you were interested in., Every time you type a text on your smartphone, you see NLP in action., You often only have to type a few letters of a word, and the texting app will suggest the correct one for you., And the more you text, the more accurate it becomes, often recognizing commonly used words and names faster than you can type them., Predictive text, autocorrect, and autocomplete have become so accurate in word processing programs, like MS Word and Google Docs, that they can make us feel like we need to go back to grammar school., Sentiment analysis is the automated process of classifying opinions in a text as positive, negative, or neutral., It’s often used to monitor sentiments on social media., You can track and analyze sentiment in comments about your overall brand, a product, particular feature, or compare your brand to your competition., Imagine you’ve just released a new product and want to detect your customers’ initial reactions., Maybe a customer tweeted discontent about your customer service., By tracking sentiment analysis, you can spot these negative comments right away and respond immediately., Text classification is a core NLP task that assigns predefined categories (tags) to a text, based on its content.  , It’s great for organizing qualitative feedback (product reviews, social media conversations, surveys, etc.) into appropriate subjects or department categories., Retently, a SaaS platform, used NLP tools to classify NPS responses and gain actionable insights in next to no time:, Retently discovered  the most relevant topics mentioned by customers, and which ones they valued most., Below, you can see that most of the responses referred to “Product Features,” followed by “Product UX” and “Customer Support” (the last two topics were mentioned mostly by Promoters)., Other interesting applications of NLP revolve around customer service automation., This concept uses AI-based technology to eliminate or reduce routine manual tasks in customer support, saving agents valuable time, and making processes more efficient., According to the Zendesk benchmark, a tech company receives +2600 support inquiries per month., Receiving large amounts of support tickets from different channels (email, social media, live chat, etc), means companies need to have a strategy in place to categorize each incoming ticket., Text classification allows companies to automatically tag incoming customer support tickets according to their topic, language, sentiment, or urgency., Then, based on these tags, they can instantly route tickets to the most appropriate pool of agents., Uber designed its own ticket routing workflow, which involves tagging tickets by Country, Language, and Type (this category includes the sub-tags Driver-Partner, Questions about Payments, Lost Items, etc), and following some prioritization rules, like sending requests from new customers (New Driver-Partners) are sent to the top of the list., A chatbot is a computer program that simulates human conversation., Chatbots use NLP to recognize the intent behind a sentence, identify relevant topics and keywords, even emotions, and come up with the best response based on their interpretation of data., As customers crave fast, personalized, and around-the-clock support experiences, chatbots have become the heroes of customer service strategies., Chatbots reduce customer waiting times by providing immediate responses and especially excel at handling routine queries (which usually represent the highest volume of customer support requests), allowing agents to focus on solving more complex issues., In fact, chatbots can solve up to 80% of routine customer support tickets., Besides providing customer support, chatbots can be used to recommend products, offer discounts, and make reservations, among many other tasks., In order to do that, most chatbots follow a simple ‘if/then’ logic (they are programmed to identify intents and associate them with a certain action), or provide a selection of options to choose from., Automatic summarization consists of reducing a text and creating a concise new version that contains its most relevant information., It can be particularly useful to summarize large pieces of unstructured data, such as academic papers., There are two different ways to use NLP for summarization:, Automatic summarization can be particularly useful for data entry, where relevant information is extracted from a product description, for example, and automatically entered into a database., The possibility of translating text and speech to different languages has always been one of the main interests in the NLP field., From the first attempts to translate text from Russian to English in the 1950s to state-of-the-art deep learning neural systems, machine translation (MT) has seen significant improvements but still presents challenges., Google Translate, Microsoft Translator, and Facebook Translation App are a few of the leading platforms for generic machine translation., In August 2019, Facebook AI English-to-German machine translation model received first place in the contest held by the Conference of Machine Learning (WMT)., The translations obtained by this model were defined by the organizers as “superhuman” and considered highly superior to the ones performed by human experts., Another interesting development in machine translation has to do with customizable machine translation systems, which are adapted to a specific domain and trained to understand the terminology associated with a particular field, such as medicine, law, and finance., Lingua Custodia, for example, is a machine translation tool dedicated to translating technical financial documents., Finally, one of the latest innovations in MT is adaptative machine translation, which consists of systems that can learn from corrections in real-time., Natural Language Generation (NLG) is a subfield of NLP designed to build computer systems or applications that can automatically produce all kinds of texts in natural language by using a semantic representation as input., Some of the applications of NLG are question answering and text summarization., In 2019, artificial intelligence company Open AI released GPT-2, a text-generation system that represented a groundbreaking achievement in AI and has taken the NLG field to a whole new level., The system was trained with a massive dataset of 8 million web pages and it’s able to generate coherent and high-quality pieces of text (like news articles, stories, or poems), given minimum prompts., The model performs better when provided with popular topics which have a high representation in the data (such as Brexit, for example), while it offers poorer results when prompted with highly niched or technical content., Still, it’s possibilities are only beginning to be explored., Now that you’ve gained some insight into the basics of NLP and its current applications in business, you may be wondering how to put NLP into practice., There are many open-source libraries designed to work with natural language processing., These libraries are free, flexible, and allow you to build a complete and customized NLP solution., However, building a whole infrastructure from scratch requires years of data science and programming experience or you may have to hire whole teams of engineers., SaaS tools, on the other hand, are ready-to-use solutions that allow you to incorporate NLP into tools you already use simply and with very little setup., Connecting SaaS tools to your favorite apps through their APIs is easy and only requires a few lines of code., It’s an excellent alternative if you don’t want to invest time and resources learning about machine learning or NLP., Take a look at the Build vs. Buy Debate to learn more., Here’s a list of the top NLP tools:, SaaS solutions like MonkeyLearn offer ready-to-use NLP templates for analyzing specific data types., In this tutorial, below, we’ll take you through how to perform sentiment analysis combined with keyword extraction, using our customized template., 1. Choose Keyword + Sentiment Analysis template, 2. Upload your text data, If you don't have a CSV, use our sample dataset., 3. Match the CSV columns to the dashboard fields, In this template, there is only one field: text., If you have more than one column in your dataset, choose the column that has the text you would like to analyze., 4. Name your workflow, 5. Wait for your data to import, 6. Explore your dashboard!, You can:, Natural language processing is transforming the way we analyze and interact with language-based data by training machines to make sense of text and speech, and perform automated tasks like translation, summarization, classification, and extraction., Not long ago, the idea of computers capable of understanding human language seemed impossible., However, in a relatively short time ― and fueled by research and developments in linguistics, computer science, and machine learning ― NLP has become one of the most promising and fastest-growing fields within AI., As technology advances, NLP is becoming more accessible., Thanks to plug-and-play NLP-based software like MonkeyLearn, it’s becoming easier for companies to create customized solutions that help automate processes and better understand their customers., Ready to get started in NLP?, Request a demo, and let us know how we can help you get started., Automate business processes and save hours of manual data processing., MonkeyLearn Inc., All rights reserved 2022]\n"]}]},{"cell_type":"code","source":["page4_sentences = []\n","URL = \"https://www.javatpoint.com/nlp\"\n","\n","page = requests.get(URL)\n","soup = BeautifulSoup(page.content, 'html.parser')\n","paragraphs = soup.find_all(\"p\")\n","\n","for paragraph in paragraphs:\n","  if paragraph.parent.find(\"a\") != None:\n","    text = npl(paragraph.get_text())\n","    for sentence in text.sents:\n","      page4_sentences.append(str(sentence))\n","\n","print(page4_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRz_tL3VQgGh","executionInfo":{"status":"ok","timestamp":1665346141766,"user_tz":180,"elapsed":2420,"user":{"displayName":"Enzo Campa","userId":"14794698325374388710"}},"outputId":"374661ef-9169-4f33-e68b-28c292d0e579"},"id":"vRz_tL3VQgGh","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[NLP tutorial provides basic and advanced concepts of the NLP tutorial., Our NLP tutorial is designed for beginners and professionals., NLP stands for Natural Language Processing, which is a part of Computer Science, Human language, and Artificial Intelligence., It is the technology that is used by machines to understand, analyse, manipulate, and interpret human's languages., It helps developers to organize knowledge for performing tasks such as translation, automatic summarization, Named Entity Recognition (NER), speech recognition, relationship extraction, and topic segmentation., (1940-1960) - Focused on Machine Translation (MT), The Natural Languages Processing started in the year 1940s., 1948 -, In the Year 1948, the first recognisable NLP application was introduced in Birkbeck College, London., 1950s -, In the Year 1950s, there was a conflicting view between linguistics and computer science., Now, Chomsky developed his first book syntactic structures and claimed that language is generative in nature., In 1957, Chomsky also introduced the idea of Generative Grammar, which is rule based descriptions of syntactic structures., (1960-1980) - Flavored with Artificial Intelligence (AI), In the year 1960 to 1980, the key developments were:, Augmented Transition Networks (ATN), Augmented Transition Networks is a finite state machine that is capable of recognizing regular languages., Case Grammar, Case Grammar was developed by Linguist Charles J. Fillmore in the year 1968., Case Grammar uses languages such as English to express the relationship between nouns and verbs by using the preposition., In Case Grammar, case roles can be defined to link certain kinds of verbs and objects., For example: \"Neha broke the mirror with the hammer\"., In this example case grammar identify Neha as an agent, mirror as a theme, and hammer as an instrument., In the year 1960 to 1980, key systems were:, SHRDLU, SHRDLU is a program written by Terry Winograd in 1968-70., It helps users to communicate with the computer and moving objects., It can handle instructions such as \"pick up the green boll\" and also answer the questions like \"What is inside the black box.\", The main importance of SHRDLU is that it shows those syntax, semantics, and reasoning about the world that can be combined to produce a system that understands a natural language., LUNAR, LUNAR is the classic example of a Natural Language database interface system that is used ATNs and Woods' Procedural Semantics., It was capable of translating elaborate natural language expressions into database queries and handle 78% of requests without errors., 1980 - Current, Till the year 1980, natural language processing systems were based on complex sets of hand-written rules., After 1980, NLP introduced machine learning algorithms for language processing., In the beginning of the year 1990s, NLP started growing faster and achieved good process accuracy, especially in English Grammar., In 1990 also, an electronic text introduced, which provided a good resource for training and examining natural language programs., Other factors may include the availability of computers with fast CPUs and more memory., The major factor behind the advancement of natural language processing was the Internet., Now, modern NLP consists of various applications, like speech recognition, machine translation, and machine text reading., When we combine all these applications then it allows the artificial intelligence to gain knowledge of the world., Let's consider the example of AMAZON ALEXA, using this robot you can ask the question to Alexa, and it will reply to you., A list of disadvantages of NLP is given below:, There are the following two components of NLP -, 1. Natural Language Understanding (NLU), Natural Language Understanding (NLU) helps the machine to understand and analyse human language by extracting the metadata from content such as concepts, entities, keywords, emotion, relations, and semantic roles., NLU mainly used in Business applications to understand the customer's problem in both spoken and written language., NLU involves the following tasks -, 2. Natural Language Generation (NLG), Natural Language Generation (NLG) acts as a translator that converts the computerized data into natural language representation., It mainly involves Text planning, Sentence planning, and Text Realization., Difference between NLU and NLG, There are the following applications of NLP -, 1., Question Answering, Question Answering focuses on building systems that automatically answer the questions asked by humans in a natural language., 2. Spam Detection, Spam detection is used to detect unwanted e-mails getting to a user's inbox., 3. Sentiment Analysis, Sentiment Analysis is also known as opinion mining., It is used on the web to analyse the attitude, behaviour, and emotional state of the sender., This application is implemented through a combination of NLP (Natural Language Processing) and statistics by assigning the values to the text (positive, negative, or natural), identify the mood of the context (happy, sad, angry, etc.), 4. Machine Translation, Machine translation is used to translate text or speech from one natural language to another natural language., Example:, Google Translator, 5., Spelling correction, Microsoft Corporation provides word processor software like MS-word, PowerPoint for the spelling correction., 6., Speech Recognition, Speech recognition is used for converting spoken words into text., It is used in applications, such as mobile, home automation, video recovery, dictating to Microsoft Word, voice biometrics, voice user interface, and so on., 7., Chatbot, Implementing the Chatbot is one of the important applications of NLP., It is used by many companies to provide the customer's chat services., 8., Information extraction, Information extraction is one of the most important applications of NLP., It is used for extracting structured information from unstructured or semi-structured machine-readable documents., 9. Natural Language Understanding (NLU), It converts a large set of text into more formal representations such as first-order logic structures that are easier for the computer programs to manipulate notations of the natural language processing., There are the following steps to build an NLP pipeline -, Step1:, Sentence Segmentation, Sentence Segment is the first step for building the NLP pipeline., It breaks the paragraph into separate sentences., Example: Consider the following paragraph -, Independence Day is one of the important festivals for every Indian citizen., It is celebrated on the 15th of August each year ever since India got independence from the British rule., The day celebrates independence in the true sense., Sentence Segment produces the following result:, Step2:, Word Tokenization, Word Tokenizer is used to break the sentence into separate words or tokens., Example:, JavaTpoint offers Corporate Training, Summer Training, Online Training, and Winter Training., Word Tokenizer generates the following result:, \"JavaTpoint\", \"offers\", \"Corporate\", \"Training\", \"Summer\", \"Training\", \"Online\", \"Training\", \"and\", \"Winter\", \"Training\", \".\", Step3:, Stemming, Stemming is used to normalize words into its base form or root form., For example, celebrates, celebrated and celebrating, all these words are originated with a single root word \"celebrate.\", The big problem with stemming is that sometimes it produces the root word which may not have any meaning., For Example, intelligence, intelligent, and intelligently, all these words are originated with a single root word \"intelligen.\", In English, the word \"intelligen\" do not have any meaning., Step 4: Lemmatization, Lemmatization is quite similar to the Stamming., It is used to group different inflected forms of the word, called Lemma., The main difference between Stemming and lemmatization is that it produces the root word, which has a meaning., For example: In lemmatization, the words intelligence, intelligent, and intelligently has a root word intelligent, which has a meaning., Step 5: Identifying Stop Words, In English, there are a lot of words that appear very frequently like \"is\", \"and\", \"the\", and \"a\"., NLP pipelines will flag these words as stop words., Stop words might be filtered out before doing any statistical analysis., Example:, He is a good boy., Step 6: Dependency Parsing, Dependency Parsing is used to find that how all the words in the sentence are related to each other., Step 7: POS tags, POS stands for parts of speech, which includes Noun, verb, adverb, and Adjective., It indicates that how a word functions with its meaning as well as grammatically within the sentences., A word has one or more parts of speech based on the context in which it is used., Example: \"Google\" something on the Internet., In the above example, Google is used as a verb, although it is a proper noun., Step 8: Named Entity Recognition (NER), Named Entity Recognition (NER) is the process of detecting the named entity such as person name, movie name, organization name, or location., Example: Steve Jobs introduced iPhone at the Macworld Conference in San Francisco, California., Step 9: Chunking, Chunking is used to collect the individual piece of information and grouping them into bigger pieces of sentences., There are the following five phases of NLP:, 1. Lexical Analysis and Morphological, The first phase of NLP is the Lexical Analysis., This phase scans the source code as a stream of characters and converts it into meaningful lexemes., It divides the whole text into paragraphs, sentences, and words., 2. Syntactic Analysis (Parsing), Syntactic Analysis is used to check grammar, word arrangements, and shows the relationship among the words., Example: Agra goes to the Poonam, 3. Semantic Analysis, Semantic analysis is concerned with the meaning representation., It mainly focuses on the literal meaning of words, phrases, and sentences., 4. Discourse Integration, Discourse Integration depends upon the sentences that proceeds it and also invokes the meaning of the sentences that follow it., 5., Pragmatic Analysis, Pragmatic is the fifth and last phase of NLP., It helps you to discover the intended effect by applying a set of rules that characterize cooperative dialogues., For Example: \"Open the door\" is interpreted as a request instead of an order., NLP is difficult because Ambiguity and Uncertainty exist in the language., Ambiguity, There are the following three ambiguity -, Lexical Ambiguity exists in the presence of two or more possible meanings of the sentence within a single word., Example:, Manya is looking for a match., In the above example, the word match refers to that either Manya is looking for a partner or Manya is looking for a match., (Cricket or other match), Syntactic Ambiguity exists in the presence of two or more possible meanings within the sentence., Example:, I saw the girl with the binocular., In the above example, did I have the binoculars?, Or did the girl have the binoculars?, Referential Ambiguity exists when you are referring to something using the pronoun., Example: Kiran went to Sunita., She said, \"I am hungry.\", In the above sentence, you do not know that who is hungry, either Kiran or Sunita., Natural Language Processing APIs allow developers to integrate human-to-machine communications and complete several useful tasks such as speech recognition, chatbots, spelling correction, sentiment analysis, etc., A list of NLP APIs is given below:, Scikit-learn: It provides a wide range of algorithms for building machine learning models in Python., Natural language Toolkit (NLTK): NLTK is a complete toolkit for all NLP techniques., Pattern: It is a web mining module for NLP and machine learning., TextBlob: It provides an easy interface to learn basic NLP tasks like sentiment analysis, noun phrase extraction, or pos-tagging., Quepy: Quepy is used to transform natural language questions into queries in a database query language., SpaCy: SpaCy is an open-source NLP library which is used for Data Extraction, Data Analysis, Sentiment Analysis, and Text Summarization., Gensim: Gensim works with large datasets and processes data streams., Before learning NLP, you must have the basic knowledge of Python., Our NLP tutorial is designed to help beginners., We assure that you will not find any problem in this NLP tutorial., But if there is any mistake or error, please post the error in the contact form., JavaTpoint offers too many high quality services., Mail us on [email protected], to get more information about given services., JavaTpoint offers college campus training on Core Java, Advance Java, .Net, Android, Hadoop, PHP, Web Technology and Python., Please mail your requirement at [email protected] Duration: 1 week to 2 week, Address: G-13, 2nd Floor, Sec-3, Noida, UP, 201301, India, Contact No: 0120-4256464, 9990449935]\n"]}]},{"cell_type":"code","execution_count":null,"id":"f82aa2e5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f82aa2e5","executionInfo":{"status":"ok","timestamp":1665341480397,"user_tz":180,"elapsed":5,"user":{"displayName":"Enzo Campa","userId":"14794698325374388710"}},"outputId":"eea8e02e-966e-4580-ec56-f788dddd3b63"},"outputs":[{"output_type":"stream","name":"stdout","text":["['While natural language processing isn’t a new science, the technology is rapidly advancing thanks to an increased interest in human-to-machine communications, plus an availability of big data, powerful computing and enhanced algorithms', 'As a human, you may speak and write in English, Spanish or Chinese', ' But a computer’s native language – known as machine code or machine language – is largely incomprehensible to most people', ' At your device’s lowest levels, communication occurs not with words but through millions of zeros and ones that produce logical actions', 'Indeed, programmers used punch cards to communicate with the first computers 70 years ago', ' This manual and arduous process was understood by a relatively small number of people', ' Now you can say, “Alexa, I like this song,” and a device playing music in your home will lower the volume and reply, “OK', ' Rating saved,” in a humanlike voice', ' Then it adapts its algorithm to play that song – and others like it – the next time you listen to that music station', 'Let’s take a closer look at that interaction', ' Your device activated when it heard you speak, understood the unspoken intent in the comment, executed an action and provided feedback in a well-formed English sentence, all in the space of about five seconds', ' The complete interaction was made possible by NLP, along with other AI elements such as machine learning and deep learning', 'The COPD Foundation uses text analytics and sentiment analysis, NLP techniques, to turn unstructured data into valuable insights', ' These findings help provide health resources and emotional support for patients and caregivers', ' Learn more about how analytics is improving the quality of life for those living with pulmonary disease', '\\n', 'Natural language processing helps computers communicate with humans in their own language and scales other language-related tasks', ' For example, NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important', 'Today’s machines can analyze more language-based data than humans, without fatigue and in a consistent, unbiased way', ' Considering the staggering amount of unstructured data that’s generated every day, from medical records to social media, automation will be critical to fully analyze text and speech data efficiently', 'Human language is astoundingly complex and diverse', ' We express ourselves in infinite ways, both verbally and in writing', ' Not only are there hundreds of languages and dialects, but within each language is a unique set of grammar and syntax rules, terms and slang', ' When we write, we often misspell or abbreviate words, or omit punctuation', ' When we speak, we have regional accents, and we mumble, stutter and borrow terms from other languages', 'While supervised and unsupervised learning, and specifically deep learning, are now widely used for modeling human language, there’s also a need for syntactic and semantic understanding and domain expertise that are not necessarily present in these machine learning approaches', ' NLP is important because it helps resolve ambiguity in language and adds useful numeric structure to the data for many downstream applications, such as\\xa0speech\\xa0recognition or text analytics', 'Learn more about natural language processing in many industries', 'How are organizations around the world using artificial intelligence and NLP', ' What are the adoption rates and future plans for these technologies', ' What are the budgets and deployment plans', ' And what business problems are being solved with NLP algorithms', ' Find out in this report from TDWI', 'People’s thoughts, research, opinions, facts and feedback transfer into the digital world through social media feeds, legal case files, electronic health records, contact center logs, warranty claims and more', ' Natural language processing uncovers the insights hidden in the word streams', 'Text analytics is a type of natural language processing that turns text into data for analysis', ' Learn how organizations in banking, health care and life sciences, manufacturing and government are using text analytics to drive better customer experiences, reduce fraud and improve society', 'Natural language processing includes many different techniques for interpreting human language, ranging from statistical and machine learning methods to rules-based and algorithmic approaches', ' We need a broad array of approaches because the text- and voice-based data varies widely, as do the practical applications', 'Basic NLP tasks include tokenization and parsing, lemmatization/stemming, part-of-speech tagging, language detection and identification of semantic relationships', ' If you ever diagramed sentences in grade school, you’ve done these tasks manually before', 'In general terms, NLP tasks break down language into shorter, elemental pieces, try to understand relationships between the pieces and explore how the pieces work together to create meaning', 'These underlying tasks are often used in higher-level NLP capabilities, such as', '\\nIn all these cases, the overarching goal is to take raw language input and use linguistics and algorithms to transform or enrich the text in such a way that it delivers greater value', 'How can you find answers in large volumes of textual data', ' By combining machine learning with natural language processing and text analytics', ' Find out how your unstructured data can be analyzed to identify issues, evaluate sentiment, detect emerging trends and spot hidden opportunities', '\\n', 'Natural language processing goes hand in hand with text analytics, which counts, groups and categorizes words to extract structure and meaning from large volumes of content', ' Text analytics is used to explore textual content and derive new variables from raw text that may be visualized, filtered, or used as inputs to predictive models or other statistical methods', 'NLP and text analytics are used together for many applications, including', 'There are many common and practical applications of NLP in our everyday lives', ' Beyond conversing with virtual assistants like Alexa or Siri, here are a few more examples', 'A subfield of NLP called natural language understanding (NLU) has begun to rise in popularity because of its potential in cognitive and AI applications', ' NLU goes beyond the structural understanding of language to interpret intent, resolve context and word ambiguity, and even generate well-formed human language on its own', ' NLU algorithms must tackle the extremely complex problem of semantic interpretation – that is, understanding the intended meaning of spoken or written language, with all the subtleties, context and inferences that we humans are able to comprehend', 'The evolution of NLP toward NLU has a lot of important implications for businesses and consumers alike', '\\xa0Imagine the power of an algorithm that can understand the meaning and nuance of human language in many contexts, from medicine to law to the classroom', ' As the volumes of unstructured information continue to grow exponentially, we will benefit from computers’ tireless ability to help us make sense of it all']\n"]}],"source":["page5_sentences = []\n","\n","URL = \"https://www.sas.com/en_us/insights/analytics/what-is-natural-language-processing-nlp.html\"\n","page = requests.get(URL)\n","soup = BeautifulSoup(page.content, 'html.parser')\n","paragraphs = soup.find_all(\"p\")\n","\n","notUsefullLinks = [\"#content-wrapper\", \"https://www.sas.com/profile/ui/\", \"https://my.sas.com/en/home.html\", \"https://my.sas.com/en/home.html\", \"https://www.sas.com/profile/user/contact.htm?locale=en_us&amp;returnURL=https://www.sas.com/en_us/home.html\"]\n","\n","for paragraph in paragraphs:\n","\n","  if paragraph.find(\"span\") == None and paragraph.find(\"small\") == None and paragraph.get_text() != '\\xa0':\n","    if paragraph.a != None:\n","      if paragraph.a[\"href\"] not in notUsefullLinks:\n","        text = re.split(r'\\.|\\!|\\?|\\;|\\:', paragraph.get_text())\n","        for sentence in text:\n","          if(sentence != '' and sentence!= '\\xa0'):\n","            page5_sentences.append(sentence)\n","    else: \n","      text = re.split(r'\\.|\\!|\\?|;|\\:', paragraph.get_text())\n","      for sentence in text:\n","        if(sentence != '' and sentence!= '\\xa0'):\n","          page5_sentences.append(sentence)\n","\n","print(page5_sentences)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}